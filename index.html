<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ViT-LASNet for Plankton Classification</title>
    <!-- Link to external CSS file -->
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>ViT-LASNet: Enhancing Plankton Classification for Real-Time Ecological Monitoring</h1>
        </div>
    </header>

    <!-- Section: Figure -->
    <section class="section">
        <div class="container">
            <img src="Fig1-ECCV_lr.png" alt="ViT-LASNet Framework" style="max-width:100%; height:auto;">
            <p><strong>Figure 1:</strong> Sample diversity captured by the Plankton Imager and location of the research vessel: a comparative display of copepods, non-copepods, and detritus.</p>
        </div>
    </section>

    <!-- Section: Links to Paper and GitHub -->
    <section id="links" class="section">
        <div class="container">
            <h2>Project Links</h2>
            <ul>
                <li><a href="https://arxiv.org/abs/xxxxxxx" target="_blank">View the Paper on ArXiv</a></li>
                <li><a href="https://github.com/yourusername/ViT-LASNet" target="_blank">GitHub Repository</a></li>
            </ul>
        </div>
    </section>

    <!-- Section: Abstract -->
    <section id="abstract" class="section">
    <div class="container">
        <h2>Abstract</h2>
        <p class="justify-text">
            The complexity of marine plankton monitoring has highlighted the limitations of conventional machine learning models, particularly when faced with long-tailed data distributions commonly found in natural environments. This paper introduces a comprehensive framework that leverages a novel dataset from the Plankton imager (Pi-10) instrument designed to enhance plankton image monitoring accuracy in a real-time application. We employ cutting-edge image classification architectures, including pre-trained Vision Transformers (ViT) and BERT Pre-training of Image Transformers (BEiT). We integrate Label-Aware Smoothing (LAS) into our training process to address the challenges of long-tailed data distributions. Further, we innovate with dynamic label-aware smoothing, which adjusts smoothing factors based on attention scores from ViTs to tailor model confidence to the significance of different image regions. The results demonstrate improvements in classification performance on the Pi-10 dataset, effectively handling long-tail distribution challenges and setting new benchmarks for real-time image classification in ecological research and biodiversity monitoring. This approach advances biodiversity monitoring and provides a scalable solution adaptable to other domains encountering similar distributional challenges.
        </p>
    </div>
</section>


    <!-- Section: Contact Information -->
    <section id="contact" class="section">
        <div class="container">
            <h2>Contact</h2>
            <p>For inquiries or collaboration, please reach out via:</p>
            <p>Email: <a href="mailto:Neftekhari@turing.ac.uk">Neftekhari@turing.ac.uk</a></p>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2024 Noushin Eftekhari</p>
        </div>
    </footer>
</body>
</html>
